import streamlit as st
import pandas as pd
import yfinance as yf
import os
import time
from io import BytesIO
import urllib.request

# =========================
# 1. ã‚¢ãƒ—ãƒªè¨­å®š
# =========================
st.set_page_config(page_title="å…¨å¸‚å ´å¯¾å¿œã‚¹ã‚­ãƒ£ãƒŠãƒ¼", layout="wide")
MY_PASSWORD = "stock testa"

# =========================
# 2. èªè¨¼æ©Ÿèƒ½
# =========================
if "auth" not in st.session_state:
    st.session_state.auth = False

if not st.session_state.auth:
    st.title("ğŸ”’ èªè¨¼")
    pwd = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
    if pwd == MY_PASSWORD:
        st.session_state.auth = True
        st.rerun()
    st.stop()

# =========================
# 3. GitHub CSV URLï¼ˆâ˜…ã“ã“é‡è¦ï¼‰
# =========================
# æ­£ã—ã„rawå½¢å¼ï¼ˆ/refs/heads/ ã¯ä¸è¦ï¼‰
GITHUB_CSV_RAW_URL = "https://raw.githubusercontent.com/watarai0202-netizen/stocktest-app-1/main/data_j.csv"

# ãƒ­ãƒ¼ã‚«ãƒ«ä¿é™ºï¼ˆä»»æ„ï¼‰
LOCAL_CSV = None
if os.path.exists("data_j.csv"):
    LOCAL_CSV = "data_j.csv"

# =========================
# 4. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
# =========================
st.sidebar.title("âš™ï¸ è¨­å®š")

target_market = st.sidebar.radio(
    "ğŸ“Š å¸‚å ´ã‚’é¸æŠ",
    ("ãƒ—ãƒ©ã‚¤ãƒ ", "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰", "ã‚°ãƒ­ãƒ¼ã‚¹"),
    index=0
)

filter_level = st.sidebar.radio(
    "ğŸ” æŠ½å‡ºãƒ¢ãƒ¼ãƒ‰",
    ("Lv.2 ç²¾é‹­ (ğŸ”¥ğŸš€)", "Lv.3 ç¥7 (TOP 7)")
)

min_trading_value = st.sidebar.slider("ğŸ’° æœ€ä½å£²è²·ä»£é‡‘ (å„„å††)", 1, 50, 3)
min_rvol = st.sidebar.slider("ğŸ“¢ å‡ºæ¥é«˜æ€¥å¢—åº¦ (å€)", 0.1, 5.0, 0.5)

debug = st.sidebar.checkbox("ğŸ§ª ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¡¨ç¤º", value=False)

# âœ… ä¿®æ­£â‘ ï¼šCSVã‚‚å—ã‘ä»˜ã‘ã‚‹
uploaded_file = st.sidebar.file_uploader("ãƒªã‚¹ãƒˆæ›´æ–°ï¼ˆCSVæ¨å¥¨ï¼‰", type=["csv", "xls", "xlsx"])


# =========================
# 5. ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================
def _market_key(market_type: str) -> str:
    if market_type == "ãƒ—ãƒ©ã‚¤ãƒ ":
        return "ãƒ—ãƒ©ã‚¤ãƒ ï¼ˆå†…å›½æ ªå¼ï¼‰"
    if market_type == "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰":
        return "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ï¼ˆå†…å›½æ ªå¼ï¼‰"
    return "ã‚°ãƒ­ãƒ¼ã‚¹ï¼ˆå†…å›½æ ªå¼ï¼‰"


@st.cache_data(ttl=3600, show_spinner=False)
def load_master_from_bytes(file_bytes: bytes, filename: str) -> pd.DataFrame:
    """CSV/XLSX/XLS ã‚’ bytes ã‹ã‚‰èª­ã¿è¾¼ã‚€ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ã‚Šï¼‰"""
    name = (filename or "").lower()

    if name.endswith(".csv"):
        bio = BytesIO(file_bytes)
        try:
            return pd.read_csv(bio)
        except UnicodeDecodeError:
            bio.seek(0)
            return pd.read_csv(bio, encoding="utf-8-sig")

    # Excel
    bio = BytesIO(file_bytes)
    try:
        return pd.read_excel(bio, engine="openpyxl")
    except Exception:
        bio.seek(0)
        # xlsã®å ´åˆ xlrd ãŒå¿…è¦ï¼ˆç’°å¢ƒã«ãªã‘ã‚Œã°ä¾‹å¤–ï¼‰
        return pd.read_excel(bio, engine="xlrd")


@st.cache_data(ttl=3600, show_spinner=False)
def load_master_from_url(url: str) -> pd.DataFrame:
    """URLã‹ã‚‰CSVã‚’å–å¾—ã—ã¦DataFrameåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ã‚Šï¼‰"""
    with urllib.request.urlopen(url) as resp:
        b = resp.read()
    filename = url.split("?")[0].split("/")[-1]  # data_j.csv ç­‰
    return load_master_from_bytes(b, filename)


@st.cache_data(ttl=3600, show_spinner=False)
def load_master_from_path(path: str) -> pd.DataFrame:
    with open(path, "rb") as f:
        b = f.read()
    return load_master_from_bytes(b, os.path.basename(path))


def get_tickers_from_df(df: pd.DataFrame, market_type="ãƒ—ãƒ©ã‚¤ãƒ "):
    """CSVé‹ç”¨æƒ³å®šã€‚å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯ï¼‹å¸‚å ´æŠ½å‡ºï¼‹ETFé™¤å¤–"""
    if df is None or df.empty:
        return [], {}

    required_cols = ["å¸‚å ´ãƒ»å•†å“åŒºåˆ†", "33æ¥­ç¨®åŒºåˆ†", "ã‚³ãƒ¼ãƒ‰", "éŠ˜æŸ„å"]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise ValueError(
            f"éŠ˜æŸ„ãƒã‚¹ã‚¿ãƒ¼ã®åˆ—åãŒé•ã„ã¾ã™ã€‚ä¸è¶³: {missing}\n"
            f"ç¾åœ¨ã®åˆ—: {list(df.columns)}\n"
            f"å¿…è¦åˆ—: {required_cols}"
        )

    search_key = _market_key(market_type)

    target_df = df[df["å¸‚å ´ãƒ»å•†å“åŒºåˆ†"] == search_key]
    target_df = target_df[target_df["33æ¥­ç¨®åŒºåˆ†"] != "ï¼"]  # ETFé™¤å¤–

    tickers = []
    ticker_info = {}
    for _, row in target_df.iterrows():
        code = str(row["ã‚³ãƒ¼ãƒ‰"]).strip()
        # "1301.0" å¯¾ç­–
        if code.endswith(".0"):
            code = code[:-2]
        t = f"{code}.T"
        tickers.append(t)
        ticker_info[t] = [str(row["éŠ˜æŸ„å"]), str(row["33æ¥­ç¨®åŒºåˆ†"])]

    return tickers, ticker_info


@st.cache_data(ttl=300, show_spinner=False)
def fetch_prices(batch, period="5d"):
    """yfinanceå–å¾—ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦é«˜é€ŸåŒ–"""
    return yf.download(
        batch,
        period=period,
        interval="1d",
        progress=False,
        group_by="ticker",
        threads=True
    )


# =========================
# 6. ãƒ¡ã‚¤ãƒ³ç”»é¢
# =========================
st.title(f"âš¡ï¸ {target_market}ãƒ»æ¿€è¾›ã‚¹ã‚­ãƒ£ãƒŠãƒ¼")


# =========================
# 7. å¸‚å ´å¤©æ°—äºˆå ±ï¼ˆ1570ï¼‰
# =========================
def check_market_condition():
    st.markdown("### ğŸŒ¡ ãƒãƒ¼ã‚±ãƒƒãƒˆå¤©æ°—äºˆå ± (æ—¥çµŒãƒ¬ãƒ 1570)")
    try:
        df_m = fetch_prices(["1570.T"], period="5d")
        if df_m is None or df_m.empty:
            return

        if isinstance(df_m.columns, pd.MultiIndex):
            s = df_m["1570.T"].dropna()
            if len(s) < 2:
                return
            latest = s.iloc[-1]
            prev = s.iloc[-2]
            curr = float(latest["Close"])
            op = float(latest["Open"])
            prev_cl = float(prev["Close"])
        else:
            s = df_m.dropna()
            if len(s) < 2:
                return
            latest = s.iloc[-1]
            prev = s.iloc[-2]
            curr = float(latest["Close"])
            op = float(latest["Open"])
            prev_cl = float(prev["Close"])

        op_ch = (curr - op) / op * 100
        day_ch = (curr - prev_cl) / prev_cl * 100

        status = "â˜ï¸ æ›‡ã‚Š"
        if op_ch > 0.5 and day_ch > 1.0:
            status = "â˜€ï¸ å¿«æ™´ (ğŸ”¥ ãƒˆãƒ¬ãƒ³ãƒ‰ä¸Šæ˜‡ä¸­)"
        elif op_ch > 1.0:
            status = "ğŸŒ¤ æ™´ã‚Œ (ğŸš€ è²·ã„å„ªå‹¢)"
        elif day_ch < -1.0 and op_ch < -0.5:
            status = "â˜”ï¸ åœŸç ‚é™ã‚Š (ğŸ“‰ æš´è½è­¦æˆ’)"
        elif day_ch < -0.5:
            status = "â˜ï¸ é›¨ (å¼±ã„)"

        st.info(f"ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: **{status}**")
        c1, c2, c3 = st.columns(3)
        c1.metric("ç¾åœ¨å€¤", f"{curr:,.0f}å††")
        c2.metric("å¯„ä»˜æ¯”", f"{op_ch:+.2f}%")
        c3.metric("å‰æ—¥æ¯”", f"{day_ch:+.2f}%")
        st.divider()

    except Exception as e:
        if debug:
            st.warning(f"å¤©æ°—äºˆå ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

check_market_condition()


# =========================
# 8. éŠ˜æŸ„ãƒã‚¹ã‚¿ãƒ¼èª­ã¿è¾¼ã¿
#    å„ªå…ˆé †ä½: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ > GitHub CSV > ãƒ­ãƒ¼ã‚«ãƒ«CSV
# =========================
tickers = []
info_db = {}
master_source = "æœªå–å¾—"
df_master = None

try:
    if uploaded_file is not None:
        b = uploaded_file.read()
        df_master = load_master_from_bytes(b, uploaded_file.name)
        tickers, info_db = get_tickers_from_df(df_master, market_type=target_market)
        master_source = f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰: {uploaded_file.name}"

    else:
        # âœ… ä¿®æ­£â‘¡ï¼šGitHub CSVã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‚ç…§
        if GITHUB_CSV_RAW_URL:
            df_master = load_master_from_url(GITHUB_CSV_RAW_URL)
            tickers, info_db = get_tickers_from_df(df_master, market_type=target_market)
            master_source = "GitHub(CSV)"

        elif LOCAL_CSV:
            df_master = load_master_from_path(LOCAL_CSV)
            tickers, info_db = get_tickers_from_df(df_master, market_type=target_market)
            master_source = f"ãƒ­ãƒ¼ã‚«ãƒ«: {LOCAL_CSV}"

        else:
            st.error("éŠ˜æŸ„ãƒã‚¹ã‚¿ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€GitHubã®raw URLã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

except Exception as e:
    st.error("éŠ˜æŸ„ãƒã‚¹ã‚¿ãƒ¼ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚CSVåˆ—åã‚„æ–‡å­—ã‚³ãƒ¼ãƒ‰ã€URLã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    if debug:
        st.exception(e)

# âœ… ä¿®æ­£â‘¢ï¼šçŠ¶æ³ãŒã™ãåˆ†ã‹ã‚‹è¡¨ç¤ºï¼ˆ0ä»¶åŸå› ã®åˆ‡ã‚Šåˆ†ã‘ï¼‰
st.sidebar.caption(f"ğŸ“Œ ãƒã‚¹ã‚¿ãƒ¼å‚ç…§å…ƒ: {master_source}")
st.sidebar.caption(f"ğŸ“Œ å¯¾è±¡éŠ˜æŸ„æ•°(å¸‚å ´æŠ½å‡ºå¾Œ): {len(tickers)}")

if df_master is not None and len(tickers) == 0:
    st.error("éŠ˜æŸ„ãƒªã‚¹ãƒˆãŒ0ä»¶ã§ã™ã€‚CSVã®å¸‚å ´è¡¨è¨˜ã‚„ETFé™¤å¤–æ¡ä»¶ã®çµæœã€å¯¾è±¡ãŒç„¡ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    st.caption("ç¢ºèªãƒã‚¤ãƒ³ãƒˆï¼š")
    st.caption("1) CSVã®ã€Œå¸‚å ´ãƒ»å•†å“åŒºåˆ†ã€ãŒ 'ãƒ—ãƒ©ã‚¤ãƒ ï¼ˆå†…å›½æ ªå¼ï¼‰' ç­‰ã¨å®Œå…¨ä¸€è‡´ã—ã¦ã„ã‚‹ã‹")
    st.caption("2) '33æ¥­ç¨®åŒºåˆ†' ãŒ 'ï¼' ã°ã‹ã‚Šã«ãªã£ã¦ã„ãªã„ã‹ï¼ˆETFé™¤å¤–ã§æ¶ˆãˆã‚‹ï¼‰")
    if debug:
        st.write("å¸‚å ´ãƒ»å•†å“åŒºåˆ†ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ï¼ˆä¸Šä½ï¼‰ï¼š")
        st.write(df_master["å¸‚å ´ãƒ»å•†å“åŒºåˆ†"].value_counts().head(10))
        st.write("33æ¥­ç¨®åŒºåˆ†ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ï¼ˆä¸Šä½ï¼‰ï¼š")
        st.write(df_master["33æ¥­ç¨®åŒºåˆ†"].value_counts().head(10))

if not tickers:
    st.stop()


# =========================
# 9. ã‚¹ã‚­ãƒ£ãƒ³å‡¦ç†
# =========================
if st.button(f"ğŸ“¡ {target_market}ã‚’ã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹", type="primary"):
    status_area = st.empty()
    bar = st.progress(0)
    results = []

    # ã¾ãšã¯ã‚ãªãŸã®é‹ç”¨æ–¹é‡ï¼ˆ30éŠ˜æŸ„ãšã¤ï¼‰ã‚’ç¶­æŒ
    batch_size = 30
    total = len(tickers)

    for i in range(0, total, batch_size):
        batch = tickers[i:i + batch_size]
        prog = min(i / total, 1.0)
        status_area.text(f"ãƒ‡ãƒ¼ã‚¿åˆ†æä¸­... {i} / {total} éŠ˜æŸ„å®Œäº†")
        bar.progress(prog)

        try:
            time.sleep(0.02)
            df = fetch_prices(batch, period="5d")
            if df is None or df.empty:
                continue

            # MultiIndexï¼ˆticker->OHLCVï¼‰å‰æã€‚å˜ä¸€è¿”å´ã®ä¿é™ºã‚‚å…¥ã‚Œã‚‹
            if not isinstance(df.columns, pd.MultiIndex):
                df = pd.concat({batch[0]: df}, axis=1)

            available = set(df.columns.levels[0].tolist())
            valid_tickers = [t for t in batch if t in available]

            for t in valid_tickers:
                try:
                    data = df[t].dropna()
                    if len(data) < 2:
                        continue

                    latest = data.iloc[-1]
                    prev = data.iloc[-2]

                    curr = float(latest["Close"])
                    op = float(latest["Open"])
                    vol = float(latest["Volume"])

                    val = (curr * vol) / 100000000  # å„„å††
                    if val < min_trading_value:
                        continue

                    avg_vol = float(data["Volume"].mean())
                    if avg_vol <= 0:
                        continue

                    rvol = vol / avg_vol
                    if rvol < min_rvol:
                        continue

                    op_ch = (curr - op) / op * 100
                    day_ch = (curr - float(prev["Close"])) / float(prev["Close"]) * 100

                    status, prio = "-", 0
                    if op_ch > 1.0 and day_ch > 2.0:
                        status, prio = "ğŸ”¥ğŸ”¥ å¤§é™½ç·š", 2
                    elif op_ch > 2.0:
                        status, prio = "ğŸš€ æ€¥ä¼¸", 1

                    if prio > 0:
                        info = info_db.get(t, ["-", "-"])
                        results.append({
                            "ã‚³ãƒ¼ãƒ‰": t.replace(".T", ""),
                            "éŠ˜æŸ„å": info[0],
                            "æ¥­ç¨®": info[1],
                            "å£²è²·ä»£é‡‘": val,
                            "å¯„ä»˜æ¯”": op_ch,
                            "å‰æ—¥æ¯”": day_ch,
                            "ç¾åœ¨å€¤": curr,
                            "çŠ¶æ…‹": status,
                            "sort": val
                        })
                except Exception as e:
                    if debug:
                        st.write(f"[{t}] ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    continue

        except Exception as e:
            if debug:
                st.write(f"ãƒãƒƒãƒå–å¾—ã‚¨ãƒ©ãƒ¼({i}-{i+batch_size}): {e}")
            continue

    bar.progress(100)
    status_area.empty()

    if results:
        df_res = pd.DataFrame(results).sort_values("sort", ascending=False)

        if filter_level == "Lv.3 ç¥7 (TOP 7)":
            df_res = df_res.head(7)
            st.markdown(f"### ğŸ’ {target_market}ãƒ»ç¥7 (TOP 7)")
        else:
            st.success(f"ğŸ’ {target_market} æŠ½å‡ºçµæœ: {len(df_res)}ä»¶")

        show_df = df_res[["çŠ¶æ…‹", "ã‚³ãƒ¼ãƒ‰", "éŠ˜æŸ„å", "å£²è²·ä»£é‡‘", "å¯„ä»˜æ¯”", "å‰æ—¥æ¯”", "ç¾åœ¨å€¤"]].copy()
        show_df["å¯„ä»˜æ¯”"] = show_df["å¯„ä»˜æ¯”"].map(lambda x: f"+{x:.2f}%" if x > 0 else f"{x:.2f}%")
        show_df["å‰æ—¥æ¯”"] = show_df["å‰æ—¥æ¯”"].map(lambda x: f"+{x:.2f}%" if x > 0 else f"{x:.2f}%")
        show_df["ç¾åœ¨å€¤"] = show_df["ç¾åœ¨å€¤"].map(lambda x: f"{x:,.0f}")
        show_df["å£²è²·ä»£é‡‘"] = show_df["å£²è²·ä»£é‡‘"].map(lambda x: f"{x:.1f}å„„å††")

        st.dataframe(show_df, use_container_width=True, hide_index=True, height=800)
    else:
        st.warning(f"{target_market}å¸‚å ´ã§æ¡ä»¶ã«åˆã†éŠ˜æŸ„ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
