import streamlit as st
import pandas as pd
import yfinance as yf
import os
import time
from io import BytesIO
import urllib.request

# =========================
# 1. ã‚¢ãƒ—ãƒªè¨­å®š
# =========================
st.set_page_config(page_title="å…¨å¸‚å ´å¯¾å¿œã‚¹ã‚­ãƒ£ãƒŠãƒ¼", layout="wide")
MY_PASSWORD = "stock testa"

# =========================
# 2. èªè¨¼æ©Ÿèƒ½
# =========================
if "auth" not in st.session_state:
    st.session_state.auth = False

if not st.session_state.auth:
    st.title("ğŸ”’ èªè¨¼")
    pwd = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
    if pwd == MY_PASSWORD:
        st.session_state.auth = True
        st.rerun()
    st.stop()

# =========================
# 3. GitHub CSV URLï¼ˆâ˜…ã“ã“é‡è¦ï¼‰
# =========================
GITHUB_CSV_RAW_URL = "https://raw.githubusercontent.com/watarai0202-netizen/stocktest-app-1/main/data_j.csv"

# ãƒ­ãƒ¼ã‚«ãƒ«ä¿é™ºï¼ˆä»»æ„ï¼‰
LOCAL_CSV = "data_j.csv" if os.path.exists("data_j.csv") else None

# =========================
# 4. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
# =========================
st.sidebar.title("âš™ï¸ è¨­å®š")

target_market = st.sidebar.radio(
    "ğŸ“Š å¸‚å ´ã‚’é¸æŠ",
    ("ãƒ—ãƒ©ã‚¤ãƒ ", "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰", "ã‚°ãƒ­ãƒ¼ã‚¹"),
    index=0
)

# é€Ÿå ±ï¼ˆ10:00ï¼‰å‘ã‘ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
st.sidebar.subheader("ğŸš€ é€Ÿå ±ï¼ˆ10:00å‘ã‘ï¼‰")
min_trading_value = st.sidebar.slider("ğŸ’° æœ€ä½å£²è²·ä»£é‡‘ (å„„å††)", 1, 50, 3)
min_rvol5 = st.sidebar.slider("ğŸ“¢ å‡ºæ¥é«˜æ€¥å¢—åº¦ rvol(5æ—¥) (å€)", 0.1, 5.0, 0.5)
require_positive_from_open = st.sidebar.checkbox("âœ… ç¾åœ¨å€¤ãŒå¯„ä»˜ã‚ˆã‚Šä¸Šï¼ˆå¯„ã‚Šå¤©æŠ‘åˆ¶ï¼‰", value=True)
min_close_strength_fast = st.sidebar.slider("ğŸ”§ é«˜å€¤åœã®å¼·ã•(é€Ÿå ±) 0-1", 0.0, 1.0, 0.60)

# æœ¬å‘½ï¼ˆç¶™ç¶šãƒ»ç¿Œæ—¥ï¼‰å‘ã‘ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
st.sidebar.subheader("ğŸ“ˆ æœ¬å‘½ï¼ˆç¶™ç¶šãƒ»ç¿Œæ—¥ï¼‰")
enable_strong_scan = st.sidebar.checkbox("æœ¬å‘½ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚‚å®Ÿè¡Œã™ã‚‹", value=True)
max_candidates_for_strong = st.sidebar.slider("æœ¬å‘½ç²¾æŸ»ã™ã‚‹å€™è£œä¸Šé™ï¼ˆå¤šã„ã¨é‡ã„ï¼‰", 30, 300, 120, step=10)
min_rvol20 = st.sidebar.slider("ğŸ“¢ å‡ºæ¥é«˜æ€¥å¢—åº¦ rvol(20æ—¥) (å€)", 1.0, 5.0, 1.5, step=0.1)
min_close_strength_strong = st.sidebar.slider("ğŸ”§ é«˜å€¤åœã®å¼·ã•(æœ¬å‘½) 0-1", 0.0, 1.0, 0.70)
need_trend_or_breakout = st.sidebar.checkbox("âœ… ãƒˆãƒ¬ãƒ³ãƒ‰ or ãƒ–ãƒ¬ã‚¤ã‚¯åˆ°é” ã‚’å¿…é ˆ", value=True)

# è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰
st.sidebar.subheader("ğŸ§¾ è¡¨ç¤º")
show_mode = st.sidebar.radio("çµæœè¡¨ç¤º", ("A: é€Ÿå ± + æœ¬å‘½ï¼ˆ2ãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰", "é€Ÿå ±ã®ã¿"))

debug = st.sidebar.checkbox("ğŸ§ª ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¡¨ç¤º", value=False)

# âœ… CSVã‚‚å—ã‘ä»˜ã‘ã‚‹
uploaded_file = st.sidebar.file_uploader("ãƒªã‚¹ãƒˆæ›´æ–°ï¼ˆCSVæ¨å¥¨ï¼‰", type=["csv", "xls", "xlsx"])


# =========================
# 5. ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================
def _market_key(market_type: str) -> str:
    if market_type == "ãƒ—ãƒ©ã‚¤ãƒ ":
        return "ãƒ—ãƒ©ã‚¤ãƒ ï¼ˆå†…å›½æ ªå¼ï¼‰"
    if market_type == "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰":
        return "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ï¼ˆå†…å›½æ ªå¼ï¼‰"
    return "ã‚°ãƒ­ãƒ¼ã‚¹ï¼ˆå†…å›½æ ªå¼ï¼‰"


@st.cache_data(ttl=3600, show_spinner=False)
def load_master_from_bytes(file_bytes: bytes, filename: str) -> pd.DataFrame:
    """CSV/XLSX/XLS ã‚’ bytes ã‹ã‚‰èª­ã¿è¾¼ã‚€ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ã‚Šï¼‰"""
    name = (filename or "").lower()

    if name.endswith(".csv"):
        bio = BytesIO(file_bytes)
        try:
            return pd.read_csv(bio)
        except UnicodeDecodeError:
            bio.seek(0)
            return pd.read_csv(bio, encoding="utf-8-sig")

    # Excel
    bio = BytesIO(file_bytes)
    try:
        return pd.read_excel(bio, engine="openpyxl")
    except Exception:
        bio.seek(0)
        return pd.read_excel(bio, engine="xlrd")


@st.cache_data(ttl=3600, show_spinner=False)
def load_master_from_url(url: str) -> pd.DataFrame:
    with urllib.request.urlopen(url) as resp:
        b = resp.read()
    filename = url.split("?")[0].split("/")[-1]
    return load_master_from_bytes(b, filename)


@st.cache_data(ttl=3600, show_spinner=False)
def load_master_from_path(path: str) -> pd.DataFrame:
    with open(path, "rb") as f:
        b = f.read()
    return load_master_from_bytes(b, os.path.basename(path))


def get_tickers_from_df(df: pd.DataFrame, market_type="ãƒ—ãƒ©ã‚¤ãƒ "):
    """å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯ï¼‹å¸‚å ´æŠ½å‡ºï¼‹ETFé™¤å¤–"""
    if df is None or df.empty:
        return [], {}

    required_cols = ["å¸‚å ´ãƒ»å•†å“åŒºåˆ†", "33æ¥­ç¨®åŒºåˆ†", "ã‚³ãƒ¼ãƒ‰", "éŠ˜æŸ„å"]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise ValueError(
            f"éŠ˜æŸ„ãƒã‚¹ã‚¿ãƒ¼ã®åˆ—åãŒé•ã„ã¾ã™ã€‚ä¸è¶³: {missing}\n"
            f"ç¾åœ¨ã®åˆ—: {list(df.columns)}\n"
            f"å¿…è¦åˆ—: {required_cols}"
        )

    search_key = _market_key(market_type)

    target_df = df[df["å¸‚å ´ãƒ»å•†å“åŒºåˆ†"] == search_key]
    target_df = target_df[target_df["33æ¥­ç¨®åŒºåˆ†"] != "ï¼"]  # ETFé™¤å¤–

    tickers = []
    ticker_info = {}
    for _, row in target_df.iterrows():
        code = str(row["ã‚³ãƒ¼ãƒ‰"]).strip()
        if code.endswith(".0"):
            code = code[:-2]
        t = f"{code}.T"
        tickers.append(t)
        ticker_info[t] = [str(row["éŠ˜æŸ„å"]), str(row["33æ¥­ç¨®åŒºåˆ†"])]

    return tickers, ticker_info


@st.cache_data(ttl=300, show_spinner=False)
def fetch_prices(batch, period="5d"):
    """yfinanceå–å¾—ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦é«˜é€ŸåŒ–"""
    return yf.download(
        batch,
        period=period,
        interval="1d",
        progress=False,
        group_by="ticker",
        threads=True
    )


@st.cache_data(ttl=300, show_spinner=False)
def fetch_prices_long(batch, period="3mo"):
    """æœ¬å‘½ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç”¨ï¼ˆå€™è£œã ã‘é•·ã‚ãƒ‡ãƒ¼ã‚¿ï¼‰"""
    return yf.download(
        batch,
        period=period,
        interval="1d",
        progress=False,
        group_by="ticker",
        threads=True
    )


def safe_close_strength(row) -> float:
    """(Close-Low)/(High-Low) 0ã€œ1ã€‚High==Lowå¯¾ç­–ã‚ã‚Š"""
    h = float(row["High"])
    l = float(row["Low"])
    c = float(row["Close"])
    rng = max(h - l, 1e-9)
    return (c - l) / rng


def bc_filters(data: pd.DataFrame):
    """
    æœ¬å‘½ï¼ˆç¶™ç¶šãƒ»ç¿Œæ—¥ï¼‰ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼åˆ¤å®š
    - rvol20
    - trend_up (5MA>25MA ã‹ã¤ Close>25MA)
    - breakout_reach (CloseãŒç›´è¿‘20æ—¥é«˜å€¤ã«è¿‘ã„/è¶…ãˆ)
    - close_strengthï¼ˆé«˜å€¤åœå¼•ã‘ï¼‰
    """
    if data is None or len(data) < 30:
        return False, {}

    latest = data.iloc[-1]

    # rvol20
    vol20 = data["Volume"].rolling(20).mean().iloc[-1]
    if pd.isna(vol20) or float(vol20) <= 0:
        return False, {}
    rvol20_val = float(latest["Volume"]) / float(vol20)

    # close strength
    cs = safe_close_strength(latest)

    # trend (5MA/25MA)
    ma5 = data["Close"].rolling(5).mean().iloc[-1]
    ma25 = data["Close"].rolling(25).mean().iloc[-1]
    trend_up = (not pd.isna(ma5)) and (not pd.isna(ma25)) and (float(ma5) > float(ma25)) and (float(latest["Close"]) > float(ma25))

    # breakout reachï¼ˆç›´è¿‘20æ—¥é«˜å€¤ï¼‰
    prev_20_high = data["High"].rolling(20).max().shift(1).iloc[-1]
    breakout_reach = False
    if not pd.isna(prev_20_high):
        breakout_reach = float(latest["Close"]) > float(prev_20_high) * 0.995  # 0.5%æ‰‹å‰ã‹ã‚‰OK

    details = {
        "rvol20": rvol20_val,
        "close_strength": cs,
        "trend_up": trend_up,
        "breakout": breakout_reach
    }
    return True, details


# =========================
# 6. ãƒ¡ã‚¤ãƒ³ç”»é¢
# =========================
st.title(f"âš¡ï¸ {target_market}ãƒ»æ¿€è¾›ã‚¹ã‚­ãƒ£ãƒŠãƒ¼")

# =========================
# 7. å¸‚å ´å¤©æ°—äºˆå ±ï¼ˆ1570ï¼‰
# =========================
def check_market_condition():
    st.markdown("### ğŸŒ¡ ãƒãƒ¼ã‚±ãƒƒãƒˆå¤©æ°—äºˆå ± (æ—¥çµŒãƒ¬ãƒ 1570)")
    try:
        df_m = fetch_prices(["1570.T"], period="5d")
        if df_m is None or df_m.empty:
            return

        if isinstance(df_m.columns, pd.MultiIndex):
            s = df_m["1570.T"].dropna()
            if len(s) < 2:
                return
            latest = s.iloc[-1]
            prev = s.iloc[-2]
            curr = float(latest["Close"])
            op = float(latest["Open"])
            prev_cl = float(prev["Close"])
        else:
            s = df_m.dropna()
            if len(s) < 2:
                return
            latest = s.iloc[-1]
            prev = s.iloc[-2]
            curr = float(latest["Close"])
            op = float(latest["Open"])
            prev_cl = float(prev["Close"])

        op_ch = (curr - op) / op * 100
        day_ch = (curr - prev_cl) / prev_cl * 100

        status = "â˜ï¸ æ›‡ã‚Š"
        if op_ch > 0.5 and day_ch > 1.0:
            status = "â˜€ï¸ å¿«æ™´ (ğŸ”¥ ãƒˆãƒ¬ãƒ³ãƒ‰ä¸Šæ˜‡ä¸­)"
        elif op_ch > 1.0:
            status = "ğŸŒ¤ æ™´ã‚Œ (ğŸš€ è²·ã„å„ªå‹¢)"
        elif day_ch < -1.0 and op_ch < -0.5:
            status = "â˜”ï¸ åœŸç ‚é™ã‚Š (ğŸ“‰ æš´è½è­¦æˆ’)"
        elif day_ch < -0.5:
            status = "â˜ï¸ é›¨ (å¼±ã„)"

        st.info(f"ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: **{status}**")
        c1, c2, c3 = st.columns(3)
        c1.metric("ç¾åœ¨å€¤", f"{curr:,.0f}å††")
        c2.metric("å¯„ä»˜æ¯”", f"{op_ch:+.2f}%")
        c3.metric("å‰æ—¥æ¯”", f"{day_ch:+.2f}%")
        st.divider()

    except Exception as e:
        if debug:
            st.warning(f"å¤©æ°—äºˆå ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

check_market_condition()

# =========================
# 8. éŠ˜æŸ„ãƒã‚¹ã‚¿ãƒ¼èª­ã¿è¾¼ã¿
# =========================
tickers = []
info_db = {}
master_source = "æœªå–å¾—"
df_master = None

try:
    if uploaded_file is not None:
        b = uploaded_file.read()
        df_master = load_master_from_bytes(b, uploaded_file.name)
        tickers, info_db = get_tickers_from_df(df_master, market_type=target_market)
        master_source = f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰: {uploaded_file.name}"
    else:
        if GITHUB_CSV_RAW_URL:
            df_master = load_master_from_url(GITHUB_CSV_RAW_URL)
            tickers, info_db = get_tickers_from_df(df_master, market_type=target_market)
            master_source = "GitHub(CSV)"
        elif LOCAL_CSV:
            df_master = load_master_from_path(LOCAL_CSV)
            tickers, info_db = get_tickers_from_df(df_master, market_type=target_market)
            master_source = f"ãƒ­ãƒ¼ã‚«ãƒ«: {LOCAL_CSV}"
        else:
            st.error("éŠ˜æŸ„ãƒã‚¹ã‚¿ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€GitHub raw URLã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
            st.stop()

except Exception as e:
    st.error("éŠ˜æŸ„ãƒã‚¹ã‚¿ãƒ¼ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚CSVåˆ—åã‚„æ–‡å­—ã‚³ãƒ¼ãƒ‰ã€URLã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    if debug:
        st.exception(e)
    st.stop()

st.sidebar.caption(f"ğŸ“Œ ãƒã‚¹ã‚¿ãƒ¼å‚ç…§å…ƒ: {master_source}")
st.sidebar.caption(f"ğŸ“Œ å¯¾è±¡éŠ˜æŸ„æ•°(å¸‚å ´æŠ½å‡ºå¾Œ): {len(tickers)}")

if df_master is not None and len(tickers) == 0:
    st.error("éŠ˜æŸ„ãƒªã‚¹ãƒˆãŒ0ä»¶ã§ã™ã€‚CSVã®å¸‚å ´è¡¨è¨˜ã‚„ETFé™¤å¤–æ¡ä»¶ã®çµæœã€å¯¾è±¡ãŒç„¡ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    if debug:
        st.write(df_master["å¸‚å ´ãƒ»å•†å“åŒºåˆ†"].value_counts().head(10))
        st.write(df_master["33æ¥­ç¨®åŒºåˆ†"].value_counts().head(10))
    st.stop()

# =========================
# 9. ã‚¹ã‚­ãƒ£ãƒ³ï¼ˆé€Ÿå ± â†’ æœ¬å‘½ï¼‰
# =========================
st.markdown("### ğŸ” ã‚¹ã‚­ãƒ£ãƒ³")
st.caption("ğŸš€ é€Ÿå ±ã¯â€œä»Šå¼·ã„â€ã‚’æ‹¾ã†ï¼ˆ10:00å‘ã‘ï¼‰ã€‚ğŸ“ˆ æœ¬å‘½ã¯é€Ÿå ±å€™è£œã‹ã‚‰â€œç¶™ç¶š/ç¿Œæ—¥æœŸå¾…â€ã‚’çµã‚‹ã€‚")

if st.button(f"ğŸ“¡ {target_market}ã‚’ã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹", type="primary"):
    status_area = st.empty()
    bar = st.progress(0)

    # --- é€Ÿå ±ï¼ˆå…¨éŠ˜æŸ„ã‚’5dã§è¦‹ã‚‹ï¼‰ ---
    fast_results = []
    batch_size = 30  # ã‚ãªãŸã®é‹ç”¨æ–¹é‡ã‚’ç¶­æŒ
    total = len(tickers)

    for i in range(0, total, batch_size):
        batch = tickers[i:i + batch_size]
        prog = min(i / total, 1.0)
        status_area.text(f"é€Ÿå ±ã‚¹ã‚­ãƒ£ãƒ³ä¸­... {i} / {total} éŠ˜æŸ„å®Œäº†")
        bar.progress(prog)

        try:
            time.sleep(0.02)
            df = fetch_prices(batch, period="5d")
            if df is None or df.empty:
                continue

            if not isinstance(df.columns, pd.MultiIndex):
                df = pd.concat({batch[0]: df}, axis=1)

            available = set(df.columns.levels[0].tolist())
            valid_tickers = [t for t in batch if t in available]

            for t in valid_tickers:
                try:
                    data = df[t].dropna()
                    if len(data) < 2:
                        continue

                    latest = data.iloc[-1]
                    prev = data.iloc[-2]

                    curr = float(latest["Close"])
                    op = float(latest["Open"])
                    vol = float(latest["Volume"])

                    # æµå‹•æ€§ï¼ˆå„„å††ï¼‰
                    val = (curr * vol) / 100000000
                    if val < min_trading_value:
                        continue

                    # rvol(5d)
                    avg_vol5 = float(data["Volume"].mean())
                    if avg_vol5 <= 0:
                        continue
                    rvol5 = vol / avg_vol5
                    if rvol5 < min_rvol5:
                        continue

                    # ä¾¡æ ¼å¤‰åŒ–
                    op_ch = (curr - op) / op * 100
                    day_ch = (curr - float(prev["Close"])) / float(prev["Close"]) * 100

                    # å¯„ã‚Šå¤©æŠ‘åˆ¶ï¼ˆä»»æ„ï¼‰
                    if require_positive_from_open and op_ch <= 0:
                        continue

                    # â€œé«˜å€¤åœã®å¼·ã•â€ï¼ˆé€Ÿå ±ã¯ç·©ã‚ã§OKï¼‰
                    cs_fast = safe_close_strength(latest)
                    if cs_fast < min_close_strength_fast:
                        continue

                    # çŠ¶æ…‹ãƒ©ãƒ™ãƒ«ï¼ˆé€Ÿå ±ç”¨ï¼‰
                    status = "ğŸš€ é€Ÿå ±"
                    if op_ch > 1.0 and day_ch > 2.0:
                        status = "ğŸ”¥ğŸ”¥ é€Ÿå ±å¼·"
                    elif op_ch > 2.0:
                        status = "ğŸš€ æ€¥ä¼¸"

                    info = info_db.get(t, ["-", "-"])
                    fast_results.append({
                        "çŠ¶æ…‹": status,
                        "ã‚³ãƒ¼ãƒ‰": t.replace(".T", ""),
                        "éŠ˜æŸ„å": info[0],
                        "å£²è²·ä»£é‡‘": val,
                        "rvol5": rvol5,
                        "å¯„ä»˜æ¯”": op_ch,
                        "å‰æ—¥æ¯”": day_ch,
                        "ç¾åœ¨å€¤": curr,
                        "é«˜å€¤åœ(é€Ÿå ±)": cs_fast,
                        "sort": val
                    })

                except Exception as e:
                    if debug:
                        st.write(f"[é€Ÿå ±:{t}] ã‚¨ãƒ©ãƒ¼: {e}")
                    continue

        except Exception as e:
            if debug:
                st.write(f"é€Ÿå ±ãƒãƒƒãƒå–å¾—ã‚¨ãƒ©ãƒ¼({i}-{i+batch_size}): {e}")
            continue

    bar.progress(100)
    status_area.empty()

    # è¡¨ç¤ºï¼šé€Ÿå ±
    st.markdown("## ğŸš€ é€Ÿå ±ï¼ˆ10:00å‘ã‘ï¼‰")
    if fast_results:
        df_fast = pd.DataFrame(fast_results).sort_values("sort", ascending=False)

        # è¡¨ç¤ºç”¨æ•´å½¢
        show_fast = df_fast[["çŠ¶æ…‹", "ã‚³ãƒ¼ãƒ‰", "éŠ˜æŸ„å", "å£²è²·ä»£é‡‘", "rvol5", "å¯„ä»˜æ¯”", "å‰æ—¥æ¯”", "ç¾åœ¨å€¤", "é«˜å€¤åœ(é€Ÿå ±)"]].copy()
        show_fast["å£²è²·ä»£é‡‘"] = show_fast["å£²è²·ä»£é‡‘"].map(lambda x: f"{x:.1f}å„„å††")
        show_fast["rvol5"] = show_fast["rvol5"].map(lambda x: f"{x:.2f}")
        show_fast["å¯„ä»˜æ¯”"] = show_fast["å¯„ä»˜æ¯”"].map(lambda x: f"+{x:.2f}%" if x > 0 else f"{x:.2f}%")
        show_fast["å‰æ—¥æ¯”"] = show_fast["å‰æ—¥æ¯”"].map(lambda x: f"+{x:.2f}%" if x > 0 else f"{x:.2f}%")
        show_fast["ç¾åœ¨å€¤"] = show_fast["ç¾åœ¨å€¤"].map(lambda x: f"{x:,.0f}")
        show_fast["é«˜å€¤åœ(é€Ÿå ±)"] = show_fast["é«˜å€¤åœ(é€Ÿå ±)"].map(lambda x: f"{x:.2f}")

        st.success(f"é€Ÿå ±ãƒ’ãƒƒãƒˆ: {len(df_fast)}ä»¶")
        st.dataframe(show_fast, use_container_width=True, hide_index=True, height=520)
    else:
        st.warning("é€Ÿå ±æ¡ä»¶ã«åˆã†éŠ˜æŸ„ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    # é€Ÿå ±ã®ã¿ãªã‚‰çµ‚äº†
    if show_mode == "é€Ÿå ±ã®ã¿" or (not enable_strong_scan) or (not fast_results):
        st.stop()

    # --- æœ¬å‘½ï¼ˆé€Ÿå ±å€™è£œã ã‘ã‚’3moã§ç²¾æŸ»ï¼‰ ---
    st.markdown("## ğŸ“ˆ æœ¬å‘½ï¼ˆç¶™ç¶šãƒ»ç¿Œæ—¥ï¼‰")
    st.caption("é€Ÿå ±å€™è£œã‹ã‚‰ã€rvol20ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ãƒ–ãƒ¬ã‚¤ã‚¯åˆ°é”ãƒ»é«˜å€¤åœã®å¼·ã•ã§â€œæ®‹ã‚‹ã‚„ã¤â€ã ã‘ã‚’æŠ½å‡ºã—ã¾ã™ã€‚")

    # å€™è£œã‚’çµã£ã¦é‡ã•ã‚’ç®¡ç†ï¼ˆå£²è²·ä»£é‡‘ä¸Šä½ã‹ã‚‰ï¼‰
    df_fast_sorted = pd.DataFrame(fast_results).sort_values("sort", ascending=False)
    df_fast_cand = df_fast_sorted.head(int(max_candidates_for_strong)).copy()

    cand_tickers = [f"{c}.T" for c in df_fast_cand["ã‚³ãƒ¼ãƒ‰"].tolist()]

    status_area = st.empty()
    bar = st.progress(0)

    strong_results = []

    # å€™è£œã¯å¤šãã¦ã‚‚æ•°ç™¾ãªã®ã§ã€ã¾ã¨ã‚ã¦å–å¾—ï¼ˆå¿…è¦ãªã‚‰åˆ†å‰²ï¼‰
    status_area.text(f"æœ¬å‘½ç²¾æŸ»ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­... å€™è£œ {len(cand_tickers)} éŠ˜æŸ„")
    try:
        df_long = fetch_prices_long(cand_tickers, period="3mo")
    except Exception as e:
        st.error("æœ¬å‘½ç”¨ã®æ ªä¾¡å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆyfinanceå´ã®ä¸€æ™‚ä¸èª¿ã®å¯èƒ½æ€§ï¼‰ã€‚")
        if debug:
            st.exception(e)
        st.stop()

    bar.progress(30)
    status_area.text("æœ¬å‘½åˆ¤å®šä¸­...")

    if df_long is None or df_long.empty:
        st.warning("æœ¬å‘½ç”¨ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã—ãŸã€‚æ™‚é–“ã‚’ãŠã„ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    if not isinstance(df_long.columns, pd.MultiIndex):
        df_long = pd.concat({cand_tickers[0]: df_long}, axis=1)

    available_long = set(df_long.columns.levels[0].tolist())

    total_cand = len(cand_tickers)
    for idx, t in enumerate(cand_tickers):
        prog = 30 + int(70 * (idx / max(total_cand, 1)))
        bar.progress(min(prog, 100))

        if t not in available_long:
            continue

        try:
            data = df_long[t].dropna()
            ok, d = bc_filters(data)
            if not ok:
                continue

            # é–¾å€¤é©ç”¨
            if d["rvol20"] < min_rvol20:
                continue
            if d["close_strength"] < min_close_strength_strong:
                continue

            if need_trend_or_breakout and not (d["trend_up"] or d["breakout"]):
                continue

            # å…ƒã®é€Ÿå ±è¡Œã‚’å¼•ãç¶™ã
            row_fast = df_fast_cand[df_fast_cand["ã‚³ãƒ¼ãƒ‰"] == t.replace(".T", "")].iloc[0].to_dict()

            # æœ¬å‘½è©•ä¾¡ã‚’ä»˜åŠ 
            row_fast["rvol20"] = d["rvol20"]
            row_fast["é«˜å€¤åœ(æœ¬å‘½)"] = d["close_strength"]
            row_fast["ãƒˆãƒ¬ãƒ³ãƒ‰"] = "âœ…" if d["trend_up"] else "-"
            row_fast["ãƒ–ãƒ¬ã‚¤ã‚¯"] = "âœ…" if d["breakout"] else "-"

            # ã‚¹ã‚³ã‚¢ä¾‹ï¼šæµå‹•æ€§Ã—æ³¨ç›®åº¦ï¼ˆä¸¦ã³æ›¿ãˆç”¨ï¼‰
            row_fast["sort_strong"] = float(row_fast["å£²è²·ä»£é‡‘"]) * float(d["rvol20"])
            row_fast["çŠ¶æ…‹"] = "ğŸ“ˆ æœ¬å‘½"
            strong_results.append(row_fast)

        except Exception as e:
            if debug:
                st.write(f"[æœ¬å‘½:{t}] ã‚¨ãƒ©ãƒ¼: {e}")
            continue

    bar.progress(100)
    status_area.empty()

    if strong_results:
        df_strong = pd.DataFrame(strong_results).sort_values("sort_strong", ascending=False)

        show_strong = df_strong[
            ["çŠ¶æ…‹", "ã‚³ãƒ¼ãƒ‰", "éŠ˜æŸ„å", "å£²è²·ä»£é‡‘", "rvol5", "rvol20", "å¯„ä»˜æ¯”", "å‰æ—¥æ¯”", "ç¾åœ¨å€¤",
             "ãƒˆãƒ¬ãƒ³ãƒ‰", "ãƒ–ãƒ¬ã‚¤ã‚¯", "é«˜å€¤åœ(é€Ÿå ±)", "é«˜å€¤åœ(æœ¬å‘½)"]
        ].copy()

        show_strong["å£²è²·ä»£é‡‘"] = show_strong["å£²è²·ä»£é‡‘"].map(lambda x: f"{float(x):.1f}å„„å††")
        show_strong["rvol5"] = show_strong["rvol5"].map(lambda x: f"{float(x):.2f}")
        show_strong["rvol20"] = show_strong["rvol20"].map(lambda x: f"{float(x):.2f}")
