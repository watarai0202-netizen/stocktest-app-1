import streamlit as st
import pandas as pd
import yfinance as yf
import os
import time
from io import BytesIO

# =========================
# 1. ã‚¢ãƒ—ãƒªè¨­å®š
# =========================
st.set_page_config(page_title="å…¨å¸‚å ´å¯¾å¿œã‚¹ã‚­ãƒ£ãƒŠãƒ¼", layout="wide")
MY_PASSWORD = "stock testa"

# =========================
# 2. èªè¨¼æ©Ÿèƒ½
# =========================
if "auth" not in st.session_state:
    st.session_state.auth = False

if not st.session_state.auth:
    st.title("ğŸ”’ èªè¨¼")
    pwd = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
    if pwd == MY_PASSWORD:
        st.session_state.auth = True
        st.rerun()
    st.stop()

# =========================
# 3. éŠ˜æŸ„ãƒã‚¹ã‚¿ãƒ¼ï¼ˆCSVé‹ç”¨ï¼‰
# =========================
# â˜…ã“ã“ã‚’å·®ã—æ›¿ãˆï¼
GITHUB_CSV_RAW_URL = "https://raw.githubusercontent.com/watarai0202-netizen/stocktest-app-1/main/data_j.csv"

# =========================
# 4. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
# =========================
st.sidebar.title("âš™ï¸ è¨­å®š")

target_market = st.sidebar.radio(
    "ğŸ“Š å¸‚å ´ã‚’é¸æŠ",
    ("ãƒ—ãƒ©ã‚¤ãƒ ", "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰", "ã‚°ãƒ­ãƒ¼ã‚¹"),
    index=0
)

filter_level = st.sidebar.radio("ğŸ” æŠ½å‡ºãƒ¢ãƒ¼ãƒ‰", ("Lv.2 ç²¾é‹­ (ğŸ”¥ğŸš€)", "Lv.3 ç¥7 (TOP 7)"))

min_trading_value = st.sidebar.slider("ğŸ’° æœ€ä½å£²è²·ä»£é‡‘ (å„„å††)", 1, 50, 3)
min_rvol = st.sidebar.slider("ğŸ“¢ å‡ºæ¥é«˜æ€¥å¢—åº¦ (å€)", 0.1, 5.0, 0.5)

debug = st.sidebar.checkbox("ğŸ§ª ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¡¨ç¤º", value=False)

# CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ä¸€æ™‚ä¸Šæ›¸ãï¼ˆGitHubæ›´æ–°å‰ã®ãƒ†ã‚¹ãƒˆç”¨ï¼‰
uploaded_csv = st.sidebar.file_uploader("ãƒªã‚¹ãƒˆæ›´æ–°ï¼ˆCSVï¼‰", type=["csv"])


# =========================
# 5. é–¢æ•°å®šç¾©
# =========================
def _market_key(market_type: str) -> str:
    if market_type == "ãƒ—ãƒ©ã‚¤ãƒ ":
        return "ãƒ—ãƒ©ã‚¤ãƒ ï¼ˆå†…å›½æ ªå¼ï¼‰"
    if market_type == "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰":
        return "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ï¼ˆå†…å›½æ ªå¼ï¼‰"
    return "ã‚°ãƒ­ãƒ¼ã‚¹ï¼ˆå†…å›½æ ªå¼ï¼‰"


@st.cache_data(ttl=3600, show_spinner=False)
def load_master_csv_from_bytes(file_bytes: bytes) -> pd.DataFrame:
    """
    CSVã®bytesã‚’DataFrameã¸ã€‚
    æ–‡å­—ã‚³ãƒ¼ãƒ‰ã¯ utf-8 / utf-8-sig ã‚’æƒ³å®šã—ã¦å¸åã€‚
    """
    bio = BytesIO(file_bytes)
    try:
        df = pd.read_csv(bio)
        return df
    except UnicodeDecodeError:
        bio.seek(0)
        df = pd.read_csv(bio, encoding="utf-8-sig")
        return df


@st.cache_data(ttl=3600, show_spinner=False)
def load_master_csv_from_path(path: str) -> pd.DataFrame:
    with open(path, "rb") as f:
        b = f.read()
    return load_master_csv_from_bytes(b)


@st.cache_data(ttl=3600, show_spinner=False)
def load_master_csv_from_url(url: str) -> pd.DataFrame:
    # pandasã®read_csv(url)ã§ã‚‚è‰¯ã„ãŒã€bytesã«å¯„ã›ã‚‹ã¨æ‰±ã„ãŒå®‰å®š
    import urllib.request
    with urllib.request.urlopen(url) as resp:
        b = resp.read()
    return load_master_csv_from_bytes(b)


def get_tickers_from_df(df: pd.DataFrame, market_type="ãƒ—ãƒ©ã‚¤ãƒ "):
    """
    CSVã®åˆ—åã¯ä»¥ä¸‹ã‚’è¦æ±‚:
      - å¸‚å ´ãƒ»å•†å“åŒºåˆ†
      - 33æ¥­ç¨®åŒºåˆ†
      - ã‚³ãƒ¼ãƒ‰
      - éŠ˜æŸ„å
    """
    if df is None or df.empty:
        return [], {}

    required_cols = ["å¸‚å ´ãƒ»å•†å“åŒºåˆ†", "33æ¥­ç¨®åŒºåˆ†", "ã‚³ãƒ¼ãƒ‰", "éŠ˜æŸ„å"]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise ValueError(
            f"CSVã«å¿…è¦ãªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“: {missing}\n"
            f"ç¾åœ¨ã®åˆ—: {list(df.columns)}\n"
            f"å¿…è¦åˆ—: {required_cols}"
        )

    search_key = _market_key(market_type)

    target_df = df[df["å¸‚å ´ãƒ»å•†å“åŒºåˆ†"] == search_key]
    target_df = target_df[target_df["33æ¥­ç¨®åŒºåˆ†"] != "ï¼"]  # ETFé™¤å¤–

    tickers = []
    ticker_info = {}

    for _, row in target_df.iterrows():
        code_raw = str(row["ã‚³ãƒ¼ãƒ‰"]).strip()

        # ã‚‚ã— "1301.0" ã¿ãŸã„ã«å…¥ã£ã¦ããŸå ´åˆã®ä¿é™º
        if code_raw.endswith(".0"):
            code_raw = code_raw[:-2]

        t = f"{code_raw}.T"
        tickers.append(t)
        ticker_info[t] = [str(row["éŠ˜æŸ„å"]), str(row["33æ¥­ç¨®åŒºåˆ†"])]

    return tickers, ticker_info


@st.cache_data(ttl=300, show_spinner=False)
def fetch_prices(batch, period="5d"):
    """
    yfinanceå–å¾—ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆåŒã˜ãƒãƒƒãƒã‚’é€£æ‰“ã—ã¦ã‚‚å†å–å¾—ã—ãªã„ï¼‰
    """
    return yf.download(
        batch,
        period=period,
        interval="1d",
        progress=False,
        group_by="ticker",
        threads=True
    )


# =========================
# 6. ãƒ¡ã‚¤ãƒ³ç”»é¢
# =========================
st.title(f"âš¡ï¸ {target_market}ãƒ»æ¿€è¾›ã‚¹ã‚­ãƒ£ãƒŠãƒ¼")


# =========================
# 7. å¸‚å ´å¤©æ°—äºˆå ±
# =========================
def check_market_condition():
    st.markdown("### ğŸŒ¡ ãƒãƒ¼ã‚±ãƒƒãƒˆå¤©æ°—äºˆå ± (æ—¥çµŒãƒ¬ãƒ 1570)")
    try:
        df_m = fetch_prices(["1570.T"], period="5d")
        if df_m is None or df_m.empty:
            return

        if isinstance(df_m.columns, pd.MultiIndex):
            s = df_m["1570.T"].dropna()
            if len(s) < 2:
                return
            latest = s.iloc[-1]
            prev = s.iloc[-2]
            curr = float(latest["Close"])
            op = float(latest["Open"])
            prev_cl = float(prev["Close"])
        else:
            s = df_m.dropna()
            if len(s) < 2:
                return
            latest = s.iloc[-1]
            prev = s.iloc[-2]
            curr = float(latest["Close"])
            op = float(latest["Open"])
            prev_cl = float(prev["Close"])

        op_ch = (curr - op) / op * 100
        day_ch = (curr - prev_cl) / prev_cl * 100

        status = "â˜ï¸ æ›‡ã‚Š"
        if op_ch > 0.5 and day_ch > 1.0:
            status = "â˜€ï¸ å¿«æ™´ (ğŸ”¥ ãƒˆãƒ¬ãƒ³ãƒ‰ä¸Šæ˜‡ä¸­)"
        elif op_ch > 1.0:
            status = "ğŸŒ¤ æ™´ã‚Œ (ğŸš€ è²·ã„å„ªå‹¢)"
        elif day_ch < -1.0 and op_ch < -0.5:
            status = "â˜”ï¸ åœŸç ‚é™ã‚Š (ğŸ“‰ æš´è½è­¦æˆ’)"
        elif day_ch < -0.5:
            status = "â˜ï¸ é›¨ (å¼±ã„)"

        st.info(f"ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: **{status}**")
        c1, c2, c3 = st.columns(3)
        c1.metric("ç¾åœ¨å€¤", f"{curr:,.0f}å††")
        c2.metric("å¯„ä»˜æ¯”", f"{op_ch:+.2f}%")
        c3.metric("å‰æ—¥æ¯”", f"{day_ch:+.2f}%")
        st.divider()

    except Exception as e:
        if debug:
            st.warning(f"å¤©æ°—äºˆå ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

check_market_condition()


# =========================
# 8. éŠ˜æŸ„ãƒã‚¹ã‚¿ãƒ¼èª­ã¿è¾¼ã¿
#    å„ªå…ˆé †ä½: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰CSV > GitHub CSV > ãƒ­ãƒ¼ã‚«ãƒ«CSV
# =========================
tickers = []
info_db = {}
master_source = "æœªå–å¾—"

try:
    if uploaded_csv is not None:
        b = uploaded_csv.read()
        df_master = load_master_csv_from_bytes(b)
        tickers, info_db = get_tickers_from_df(df_master, market_type=target_market)
        master_source = f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰: {uploaded_csv.name}"

    elif GITHUB_CSV_RAW_URL:
        df_master = load_master_csv_from_url(GITHUB_CSV_RAW_URL)
        tickers, info_db = get_tickers_from_df(df_master, market_type=target_market)
        master_source = "GitHub(CSV)"

    elif LOCAL_CSV:
        df_master = load_master_csv_from_path(LOCAL_CSV)
        tickers, info_db = get_tickers_from_df(df_master, market_type=target_market)
        master_source = f"ãƒ­ãƒ¼ã‚«ãƒ«: {LOCAL_CSV}"

    else:
        st.error("éŠ˜æŸ„ãƒã‚¹ã‚¿ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€GitHubã®raw URLã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

except Exception as e:
    st.error("éŠ˜æŸ„ãƒã‚¹ã‚¿ãƒ¼(CSV)ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚CSVã®åˆ—åã‚„æ–‡å­—ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    if debug:
        st.exception(e)

st.sidebar.caption(f"ğŸ“Œ ãƒã‚¹ã‚¿ãƒ¼å‚ç…§å…ƒ: {master_source}")
st.sidebar.caption(f"ğŸ“Œ å¯¾è±¡éŠ˜æŸ„æ•°(å¸‚å ´æŠ½å‡ºå¾Œ): {len(tickers)}")


# =========================
# 9. ã‚¹ã‚­ãƒ£ãƒ³å‡¦ç†
# =========================
if tickers and st.button(f"ğŸ“¡ {target_market}ã‚’ã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹", type="primary"):
    status_area = st.empty()
    bar = st.progress(0)
    results = []

    total = len(tickers)

    # ãƒãƒƒãƒå›æ•°ã‚’æ¸›ã‚‰ã—ãŸæ–¹ãŒé€Ÿã„ã“ã¨ãŒå¤šã„ã®ã§60ã‚’åŸºæœ¬ã«
    batch_size = 60 if total >= 60 else total
    period = "5d"

    for i in range(0, total, batch_size):
        batch = tickers[i:i + batch_size]
        prog = min(i / total, 1.0)
        status_area.text(f"ãƒ‡ãƒ¼ã‚¿åˆ†æä¸­... {i} / {total} éŠ˜æŸ„å®Œäº†")
        bar.progress(prog)

        try:
            time.sleep(0.02)
            df = fetch_prices(batch, period=period)
            if df is None or df.empty:
                continue

            # MultiIndexæƒ³å®šï¼ˆtickerâ†’OHLCVï¼‰
            if not isinstance(df.columns, pd.MultiIndex):
                # å˜ä¸€Tickerè¿”å´ã®ä¿é™º
                df = pd.concat({batch[0]: df}, axis=1)

            available = set(df.columns.levels[0].tolist())
            valid_tickers = [t for t in batch if t in available]

            for t in valid_tickers:
                try:
                    data = df[t].dropna()
                    if len(data) < 2:
                        continue

                    latest = data.iloc[-1]
                    prev = data.iloc[-2]

                    curr = float(latest["Close"])
                    op = float(latest["Open"])
                    vol = float(latest["Volume"])

                    val = (curr * vol) / 100000000  # å„„å††
                    if val < min_trading_value:
                        continue

                    avg_vol = float(data["Volume"].mean())
                    if avg_vol <= 0:
                        continue

                    rvol = vol / avg_vol
                    if rvol < min_rvol:
                        continue

                    op_ch = (curr - op) / op * 100
                    day_ch = (curr - float(prev["Close"])) / float(prev["Close"]) * 100

                    status, prio = "-", 0
                    if op_ch > 1.0 and day_ch > 2.0:
                        status, prio = "ğŸ”¥ğŸ”¥ å¤§é™½ç·š", 2
                    elif op_ch > 2.0:
                        status, prio = "ğŸš€ æ€¥ä¼¸", 1

                    if prio > 0:
                        info = info_db.get(t, ["-", "-"])
                        results.append({
                            "ã‚³ãƒ¼ãƒ‰": t.replace(".T", ""),
                            "éŠ˜æŸ„å": info[0],
                            "æ¥­ç¨®": info[1],
                            "å£²è²·ä»£é‡‘": val,
                            "å¯„ä»˜æ¯”": op_ch,
                            "å‰æ—¥æ¯”": day_ch,
                            "ç¾åœ¨å€¤": curr,
                            "çŠ¶æ…‹": status,
                            "sort": val
                        })

                except Exception as e:
                    if debug:
                        st.write(f"[{t}] ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    continue

        except Exception as e:
            if debug:
                st.write(f"ãƒãƒƒãƒå–å¾—ã‚¨ãƒ©ãƒ¼({i}-{i+batch_size}): {e}")
            continue

    bar.progress(100)
    status_area.empty()

    if results:
        df_res = pd.DataFrame(results).sort_values("sort", ascending=False)

        if filter_level == "Lv.3 ç¥7 (TOP 7)":
            df_res = df_res.head(7)
            st.markdown(f"### ğŸ’ {target_market}ãƒ»ç¥7 (TOP 7)")
        else:
            st.success(f"ğŸ’ {target_market} æŠ½å‡ºçµæœ: {len(df_res)}ä»¶")

        show_df = df_res[["çŠ¶æ…‹", "ã‚³ãƒ¼ãƒ‰", "éŠ˜æŸ„å", "å£²è²·ä»£é‡‘", "å¯„ä»˜æ¯”", "å‰æ—¥æ¯”", "ç¾åœ¨å€¤"]].copy()
        show_df["å¯„ä»˜æ¯”"] = show_df["å¯„ä»˜æ¯”"].map(lambda x: f"+{x:.2f}%" if x > 0 else f"{x:.2f}%")
        show_df["å‰æ—¥æ¯”"] = show_df["å‰æ—¥æ¯”"].map(lambda x: f"+{x:.2f}%" if x > 0 else f"{x:.2f}%")
        show_df["ç¾åœ¨å€¤"] = show_df["ç¾åœ¨å€¤"].map(lambda x: f"{x:,.0f}")
        show_df["å£²è²·ä»£é‡‘"] = show_df["å£²è²·ä»£é‡‘"].map(lambda x: f"{x:.1f}å„„å††")

        st.dataframe(show_df, use_container_width=True, hide_index=True, height=800)
    else:
        st.warning(f"{target_market}å¸‚å ´ã§æ¡ä»¶ã«åˆã†éŠ˜æŸ„ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
